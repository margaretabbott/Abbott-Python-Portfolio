{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\marga\\anaconda3\\lib\\site-packages (3.8.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\marga\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\marga\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\marga\\anaconda3\\lib\\site-packages (from spacy) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\marga\\anaconda3\\lib\\site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\marga\\anaconda3\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\marga\\anaconda3\\lib\\site-packages (from spacy) (8.3.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\marga\\anaconda3\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\marga\\anaconda3\\lib\\site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\marga\\anaconda3\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\marga\\anaconda3\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\marga\\anaconda3\\lib\\site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\marga\\anaconda3\\lib\\site-packages (from spacy) (4.66.5)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\marga\\anaconda3\\lib\\site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\marga\\anaconda3\\lib\\site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\marga\\anaconda3\\lib\\site-packages (from spacy) (2.8.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\marga\\anaconda3\\lib\\site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\marga\\anaconda3\\lib\\site-packages (from spacy) (75.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\marga\\anaconda3\\lib\\site-packages (from spacy) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\marga\\anaconda3\\lib\\site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\marga\\anaconda3\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\marga\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\marga\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\marga\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\marga\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\marga\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\marga\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\marga\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.12.14)\n",
      "Requirement already satisfied: blis<1.3.0,>=1.2.0 in c:\\users\\marga\\anaconda3\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.2.1)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\marga\\anaconda3\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\marga\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\marga\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\marga\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\marga\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\marga\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.3)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\marga\\anaconda3\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 0.8/12.8 MB 5.6 MB/s eta 0:00:03\n",
      "     -------- ------------------------------- 2.6/12.8 MB 7.6 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 4.7/12.8 MB 8.4 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 7.3/12.8 MB 9.2 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 9.7/12.8 MB 9.7 MB/s eta 0:00:01\n",
      "     --------------------------------------  12.6/12.8 MB 10.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 9.7 MB/s eta 0:00:00\n",
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'quick', 'brown', 'fox', 'does', \"n't\", 'jump', 'over', 'the', 'lazy', 'dog', '.', 'Natural', 'Language', 'Processing', 'is', 'fascinating', '!']\n"
     ]
    }
   ],
   "source": [
    "nlp=spacy.load('en_core_web_sm')\n",
    "my_statement=\"The quick brown fox doesn't jump over the lazy dog. Natural Language Processing is fascinating!\"\n",
    "my_statement_nlp=nlp(my_statement)\n",
    "tokens_spacy=[token.text for token in my_statement_nlp]\n",
    "print(tokens_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The - the: fox:Definite=Def|PronType=Art\n",
      "quick - quick: fox:Degree=Pos\n",
      "brown - brown: fox:Degree=Pos\n",
      "fox - fox: jump:Number=Sing\n",
      "does - do: jump:Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\n",
      "n't - not: jump:Polarity=Neg\n",
      "jump - jump: jump:VerbForm=Inf\n",
      "over - over: jump:\n",
      "the - the: dog:Definite=Def|PronType=Art\n",
      "lazy - lazy: dog:Degree=Pos\n",
      "dog - dog: over:Number=Sing\n",
      ". - .: jump:PunctType=Peri\n",
      "Natural - Natural: Language:Number=Sing\n",
      "Language - Language: Processing:Number=Sing\n",
      "Processing - processing: is:Number=Sing\n",
      "is - be: is:Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\n",
      "fascinating - fascinating: is:Degree=Pos\n",
      "! - !: is:PunctType=Peri\n"
     ]
    }
   ],
   "source": [
    "for token in my_statement_nlp:\n",
    "    print(f\"{token.text} - {token.lemma_}: {token.head}:{token.morph}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SpaCy tokenizes text by splitting it into words, punctuation, and special characters. Each token is assigned attributes like part of speech (POS), lemma (base form), and morphological features. This structured processing allows for deeper language understanding and enables tasks like dependency parsing, named entity recognition (NER), and sentiment analysis.\n",
    "\n",
    "SpaCy treats punctuation as separate tokens, meaning that periods, commas, exclamation marks, and other punctuation marks are not attached to words. Periods and exclamation marks share the same morphological feature of PunctType=peri.\n",
    "\n",
    "Contractions are broken into separate tokens for better analysis. By separating contractions, SpaCy ensures more accurate lemmatization, part-of-speech tagging, and syntactic parsing, making it easier to analyze words and sentence meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The - DET: DT\n",
      "quick - ADJ: JJ\n",
      "brown - ADJ: JJ\n",
      "fox - NOUN: NN\n",
      "does - AUX: VBZ\n",
      "n't - PART: RB\n",
      "jump - VERB: VB\n",
      "over - ADP: IN\n",
      "the - DET: DT\n",
      "lazy - ADJ: JJ\n",
      "dog - NOUN: NN\n",
      ". - PUNCT: .\n",
      "Natural - PROPN: NNP\n",
      "Language - PROPN: NNP\n",
      "Processing - NOUN: NN\n",
      "is - AUX: VBZ\n",
      "fascinating - ADJ: JJ\n",
      "! - PUNCT: .\n"
     ]
    }
   ],
   "source": [
    "for token in my_statement_nlp:\n",
    "    print(f\"{token.text} - {token.pos_}: {token.tag_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"quick\" -> ADJ (Adjective)\n",
    "\n",
    "\"jumps\" -> VERB (Verb)\n",
    "\n",
    "\"is\" -> AUX (Auxiliary Verb)\n",
    "\n",
    "POS tagging provides structural and grammatical insights into a sentence, it is good for error correction, identifying the mean, and accurate translation in NLP applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barack Obama: PERSON (People, including fictional)\n",
      "44th: ORDINAL (\"first\", \"second\", etc.)\n",
      "the United States: GPE (Countries, cities, states)\n",
      "Hawaii: GPE (Countries, cities, states)\n"
     ]
    }
   ],
   "source": [
    "my_new_statement=\"Barack Obama was the 44th President of the United States. He was born in Hawaii.\"\n",
    "my_new_statement_nlp=nlp(my_new_statement)\n",
    "for ent in my_new_statement_nlp.ents:\n",
    "    print(f\"{ent.text}: {ent.label_} ({spacy.explain(ent.label_)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SpaCy reconizes a lot of entities, such as person, geopolitical entity (city, country, states), organizations, ordinal numbers, cardinal numbers, etc. \n",
    "\n",
    "\"Barack Obama\"-> PERSON\n",
    "\n",
    "\"Hawaii\" -> GPE (Geopolitical Entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_statement=\"The Arctic Monkeys released the AM album in 2013.\"\n",
    "chosen_statement_nlp=nlp(chosen_statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Arctic Monkeys: ORG (Companies, agencies, institutions, etc.)\n",
      "2013: DATE (Absolute or relative dates or periods)\n"
     ]
    }
   ],
   "source": [
    "for ent in chosen_statement_nlp.ents:\n",
    "    print(f\"{ent.text}: {ent.label_} ({spacy.explain(ent.label_)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The - DET: DT\n",
      "Arctic - PROPN: NNP\n",
      "Monkeys - PROPN: NNP\n",
      "released - VERB: VBD\n",
      "the - DET: DT\n",
      "AM - PROPN: NNP\n",
      "album - NOUN: NN\n",
      "in - ADP: IN\n",
      "2013 - NUM: CD\n",
      ". - PUNCT: .\n"
     ]
    }
   ],
   "source": [
    "for token in chosen_statement_nlp:\n",
    "    print(f\"{token.text} - {token.pos_}: {token.tag_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "typo_statement=\"The arctic monkeys relleased the am album in2013.\"\n",
    "typo_statement_nlp=nlp(typo_statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arctic: LOC (Non-GPE locations, mountain ranges, bodies of water)\n"
     ]
    }
   ],
   "source": [
    "for ent in typo_statement_nlp.ents:\n",
    "    print(f\"{ent.text}: {ent.label_} ({spacy.explain(ent.label_)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The - DET: DT\n",
      "arctic - ADJ: JJ\n",
      "monkeys - NOUN: NNS\n",
      "relleased - VERB: VBD\n",
      "the - DET: DT\n",
      "am - PROPN: NNP\n",
      "album - PROPN: NNP\n",
      "in2013 - PROPN: NNP\n",
      ". - PUNCT: .\n"
     ]
    }
   ],
   "source": [
    "for token in typo_statement_nlp:\n",
    "    print(f\"{token.text} - {token.pos_}: {token.tag_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created a new sentance and ran it once with no typos and proper capitalization and as expected, everything was identitfied correctly. \"Arctic Monkeys\" and \"AM\" was a proper noun and 2013 was a number. \n",
    "\n",
    "When I made the proper nouns lowercase, \"AM\" was still labeled a proper noun, but \"arctic\" and 'monkey' were labeled as an adjective and a noun, respectively  â€” most likely because both of these words are regular words regardless. Misspelling \"released\" did not cause any problems, but not including a space between \"in\" and \"2013\" made SpaCy identify \"in2013\" as a proper noun. I think the misspelling of \"released\" was close enough to the real spelling that SpaCy did not have an issue, but \"in2013\" was not recognized, so it was labeled as a proper noun."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
